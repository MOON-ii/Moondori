import streamlit as st
import os
from openai import OpenAI

# ---------------------
# ğŸ¯ ì¥ì†Œë³„ ì´ë¯¸ì§€ & ì„¤ëª… ì‚¬ì „
# ---------------------
place_images = {
    "ì˜¤í˜ë¼ í•˜ìš°ìŠ¤": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/40/Sydney_Opera_House_Sails.jpg",
        "desc": "ì‹œë“œë‹ˆì˜ ëœë“œë§ˆí¬! ë…íŠ¹í•œ ì§€ë¶• ë””ìì¸ìœ¼ë¡œ ì„¸ê³„ì ìœ¼ë¡œ ìœ ëª…í•œ ê³µì—° ì˜ˆìˆ  ê³µê°„ì´ì—ìš”."
    },
    "í•˜ë²„ ë¸Œë¦¬ì§€": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/b/bb/Sydney_Harbour_Bridge_night.jpg",
        "desc": "ì‹œë“œë‹ˆ í•­êµ¬ë¥¼ ì‡ëŠ” ê±°ëŒ€í•œ ì² ì œ ì•„ì¹˜í˜• ë‹¤ë¦¬. ë„ë³´ë¡œ ê±´ë„ ìˆ˜ë„ ìˆì–´ìš”!"
    },
    "ë³¸ë‹¤ì´ ë¹„ì¹˜": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/5/5a/Bondi_Beach_aerial.jpg",
        "desc": "ì„œí•‘, ì‚°ì±…, ì—¬ìœ ë¡œìš´ í•˜ë£¨ ë³´ë‚´ê¸°ì— ì™„ë²½í•œ ì•„ë¦„ë‹¤ìš´ í•´ë³€ì´ì—ìš”."
    },
    "íƒ€ë¡±ê°€ ë™ë¬¼ì›": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/41/Taronga_Zoo_skyline.jpg",
        "desc": "ì½”ì•Œë¼, ìº¥ê±°ë£¨ë¥¼ ì§ì ‘ ë³¼ ìˆ˜ ìˆëŠ” ì‹œë“œë‹ˆ ìµœê³ ì˜ ë™ë¬¼ì›!"
    },
    "ë¸”ë£¨ë§ˆìš´í‹´": {
        "image": "https://upload.wikimedia.org/wikipedia/commons/4/47/Three_Sisters_BM_NSW_Australia.jpg",
        "desc": "ì¥ì—„í•œ ìì—° ì ˆê²½ê³¼ 'ì„¸ ìë§¤ ë°”ìœ„'ë¡œ ìœ ëª…í•œ êµ­ë¦½ê³µì›. ë‹¹ì¼ì¹˜ê¸° ì—¬í–‰ìœ¼ë¡œ ì¸ê¸°!"
    }
}

# ---------------------
# ğŸï¸ ì•± ì†Œê°œ
# ---------------------
st.title("ğŸ’¬ ì‹œë“œë‹ˆ ì—¬í–‰ ê°€ì´ë“œ ì±—ë´‡")
st.write(
    "âœ¨ğŸ¦˜ğŸ¨ì•ˆë…•í•˜ì„¸ìš”! ê·€ì—¬ìš´ ë¬¸ë„ë¦¬ì˜ í˜¸ì£¼ ì‹œë“œë‹ˆ ì—¬í–‰ ê°€ì´ë“œì— ì˜¤ì‹ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!! ğŸ¨ğŸ¦˜âœ¨"
    "GPT-3.5ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—¬ëŸ¬ë¶„ì˜ ì—¬í–‰ì„ ë” ë˜‘ë˜‘í•˜ê³  ì¦ê²ê²Œ ë§Œë“¤ì–´ì¤„ ìŠ¤ë§ˆíŠ¸ ì±—ë´‡ì´ì—ìš”!"
)

st.markdown("""
### ğŸ¨ ì‹œë“œë‹ˆëŠ” ì–´ë–¤ ê³³ì¸ê°€ìš”?

ì‹œë“œë‹ˆëŠ” í˜¸ì£¼ì˜ ëŒ€í‘œì ì¸ ë„ì‹œì´ì, ì„¸ê³„ì ìœ¼ë¡œ ì‚¬ë‘ë°›ëŠ” ì—¬í–‰ì§€ì˜ˆìš”.  
ì•„ë¦„ë‹¤ìš´ í•´ë³€, ì›…ì¥í•œ ì˜¤í˜ë¼ í•˜ìš°ìŠ¤, ë‹¤ì–‘í•œ ë¬¸í™”ì™€ ë§›ì§‘, ê·¸ë¦¬ê³  ì—¬ìœ ë¡œìš´ ë¼ì´í”„ìŠ¤íƒ€ì¼ê¹Œì§€ ëª¨ë‘ ê°–ì¶˜ ë„ì‹œëë‹ˆë‹¤.
ë‚¨ë°˜êµ¬ì— ìœ„ì¹˜í•˜ì—¬, ë¶ë°˜êµ¬ì™€ëŠ” ë‹¤ë¥¸ ê³„ì ˆì„ ì¦ê¸¸ ìˆ˜ ìˆì–´ìš” c:
""")

# ---------------------
# ğŸ”‘ API í‚¤ ì…ë ¥
# ---------------------
openai_api_key = st.text_input("ğŸ” OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
if not openai_api_key:
    st.info("API í‚¤ë¥¼ ì…ë ¥í•˜ì‹œë©´ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”!", icon="ğŸ”‘")
    st.stop()
else:
    os.environ["OPENAI_API_KEY"] = openai_api_key
    client = OpenAI()

# ---------------------
# âœˆï¸ ì—¬í–‰ ì •ë³´ ì…ë ¥
# ---------------------
travel_days = st.slider("â³ ì—¬í–‰ì€ ë©°ì¹  ì˜ˆì •ì¸ê°€ìš”?", 1, 14, 4)

with st.expander("ğŸ’ ì—¬í–‰ ìŠ¤íƒ€ì¼ ì„ íƒ"):
    travel_styles = st.multiselect(
        "ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥!",
        ["ë§›ì§‘ íƒë°©", "ìì—° íë§", "ë¬¸í™” ì²´í—˜", "ì‚¬ì§„ ì°ê¸°", "ì‡¼í•‘", "í˜¼ì ì—¬í–‰", "ê°€ì¡± ì—¬í–‰", "ì»¤í”Œ ì—¬í–‰"]
    )

# ---------------------
# ğŸ’¬ ì´ì „ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ---------------------
# ğŸ—ºï¸ GPTë¡œ ì—¬í–‰ ì¼ì • ì¶”ì²œ
# ---------------------
if st.button("ğŸ—ºï¸ ë‚˜ë§Œì˜ ì—¬í–‰ ì¼ì • ì¶”ì²œë°›ê¸°"):
    if not travel_styles:
        st.warning("ì—¬í–‰ ìŠ¤íƒ€ì¼ì„ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”!")
    else:
        user_prompt = f"""
        ì €ëŠ” {travel_days}ì¼ ë™ì•ˆ ì‹œë“œë‹ˆ ì—¬í–‰ì„ í•  ì˜ˆì •ì…ë‹ˆë‹¤.
        ì—¬í–‰ ìŠ¤íƒ€ì¼ì€ {', '.join(travel_styles)} ì…ë‹ˆë‹¤.
        ì´ ìŠ¤íƒ€ì¼ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ê³¼ ì¶”ì²œ ì¥ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
        """

        st.session_state.messages.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        try:
            stream = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],
                stream=True,
            )

            with st.chat_message("assistant"):
                response = st.write_stream(stream)

            st.session_state.messages.append({"role": "assistant", "content": response})

            # ğŸ” GPT ì‘ë‹µ ì¤‘ ì¥ì†Œ ì´ë¦„ í¬í•¨ëœ ê²ƒ ì°¾ê¸°
            for place, data in place_images.items():
                if place in response:
                    st.image(data["image"], caption=place, use_column_width=True)
                    st.markdown(f"ğŸ“ {data['desc']}")

        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆì–´ìš”: {e}")

# ---------------------
# ğŸ’¬ ììœ  ì§ˆë¬¸ ì…ë ¥
# ---------------------
if prompt := st.chat_input("ì‹œë“œë‹ˆ ì—¬í–‰ì´ ê¶ê¸ˆí•œê°€ìš”? ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        stream = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        )

        with st.chat_message("assistant"):
            response = st.write_stream(stream)

        st.session_state.messages.append({"role": "assistant", "content": response})

        for place, data in place_images.items():
            if place in response:
                st.image(data["image"], caption=place, use_column_width=True)
                st.markdown(f"ğŸ“ {data['desc']}")

    except Exception as e:
        st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
